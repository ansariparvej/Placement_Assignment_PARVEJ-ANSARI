{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8c1a51",
   "metadata": {},
   "source": [
    "## Question_4_Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16802449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a724bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load CSV file:\n",
    "\n",
    "csv_file = 'Question_2_Solution.csv'\n",
    "\n",
    "# Saving text in a Variable:\n",
    "\n",
    "text = \"\"\n",
    "with open(csv_file, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        text += ' '.join(row) + '\\n'\n",
    "\n",
    "# Print the text:\n",
    "#print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c484d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Haijun Zhang, Gang L iu, Tommy W. S. Chow, and Wenyin Liu, “Textual \n",
      "and Visual Content -Based Anti -Phishing A Bayesian Approach”, I EEE 2011  \n",
      "[6] J. James, L. S andhya and C. Thomas, \"Detection of phishing URLs using \n",
      "machine learning techniques,\" in 2013 International Conference o n Co ntrol \n",
      "Communication and Computing (ICCC), 2013.  \n",
      "and Mobile Communication Conference (IEMCON), 7th Annual. The summary of the Machine  learning \n",
      "models applied is shown in fig  \n",
      " \n",
      "Algorithms  Accura cy \n",
      "CNN LSTM           57.85 % \n",
      "CNN BI -LSTM          56.36 % \n",
      "Logist ic regression           91.89 % \n",
      "XGBoost             92% \n",
      " \n",
      " \n",
      "V. DISCU SSION  \n",
      " \n",
      "SL.NO  Algorithm  Accuracy  Limitations  \n",
      "    1 Online -toolbar \n",
      "algorithm     \n",
      "     96% Limited  to \n",
      "Banking \n",
      "URL ’s \n",
      "    2  \n",
      "Gold phish         \n",
      "     90% Less secure  \n",
      "Electronic copy available at: https://ssrn.com/abstract=4208185\n",
      "4 algorithm  \n",
      " \n",
      "    3 C4.5 data mining \n",
      "algorithm       \n",
      "    82.6%  Time \n",
      "consuming  \n",
      "    4 Data mining \n",
      "algorithm using \n",
      "python and Django   \n",
      "       - Short term \n",
      "phishing \n",
      "websites  \n",
      "    5 matching algorithm \n",
      "using Blacklist & \n",
      "Whitelist Approach   \n",
      "  96.23%  detection of \n",
      "some \n",
      "minimal \n",
      "false \n",
      "positive and \n",
      "false \n",
      "negative \n",
      "results  \n",
      "    6 \n",
      "Rando m forest  \n",
      "Algorithm  \n",
      "  \n",
      " \n",
      "     96% Consider \n",
      "only fe w \n",
      "features  \n",
      " \n",
      " \n",
      "The previous works of this project de tects the phishing \n",
      "websites using data mining techniques , toolbars e tc. B. Gupta.” Comparative analysis of \n",
      "features -based machine  learning approaches for phishing detection.” \n",
      "Comp uting for Sustainable Global Development (INDIACom), 2016 3rd \n",
      "International Conference on.IEEE, 2016,  \n",
      " [8] Hawanna, Var sharani Ramda s, V. Y. Kulkarni, and R. A. Rane.” A novel \n",
      "algorithm to detect phishing URLs.” Automatic Control and Dynamic \n",
      "Optimizati on T echniques (ICACDOT), International Conference on.\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(text, num_sentences):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords from the sentences\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentences = [sentence for sentence in sentences if sentence.lower() not in stop_words]\n",
    "    \n",
    "    # Calculate the word frequency distribution\n",
    "    word_frequencies = FreqDist(nltk.word_tokenize(text.lower()))\n",
    "    \n",
    "    # Assign scores to each sentence based on word frequencies\n",
    "    scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word in word_frequencies:\n",
    "                if i in scores:\n",
    "                    scores[i] += word_frequencies[word]\n",
    "                else:\n",
    "                    scores[i] = word_frequencies[word]\n",
    "    \n",
    "    # Sort the sentences by their scores in descending order\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Select the top 'num_sentences' sentences as the summary\n",
    "    summary_sentences = [sentences[i] for i, _ in sorted_scores[:num_sentences]]\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Input:\n",
    "text\n",
    "num_sentences = 3\n",
    "\n",
    "summary = summarize_text(text, num_sentences)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2bdbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
