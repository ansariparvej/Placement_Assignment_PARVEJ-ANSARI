{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEzD36BFvU_1",
    "outputId": "744c6d04-bca9-4ddc-a062-239890e4f744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 6s 10ms/step - loss: 0.1351 - accuracy: 0.9585 - val_loss: 0.0531 - val_accuracy: 0.9838\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9885 - val_loss: 0.0526 - val_accuracy: 0.9855\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0454 - val_accuracy: 0.9852\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0485 - val_accuracy: 0.9876\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0404 - val_accuracy: 0.9888\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0410 - val_accuracy: 0.9896\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0388 - val_accuracy: 0.9909\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0386 - val_accuracy: 0.9914\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0442 - val_accuracy: 0.9902\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0544 - val_accuracy: 0.9886\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0436 - val_accuracy: 0.9912\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0463 - val_accuracy: 0.9901\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0531 - val_accuracy: 0.9903\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0568 - val_accuracy: 0.9893\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0503 - val_accuracy: 0.9910\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0546 - val_accuracy: 0.9903\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0607 - val_accuracy: 0.9894\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0499 - val_accuracy: 0.9916\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0564 - val_accuracy: 0.9905\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 8.0562e-04 - accuracy: 0.9997 - val_loss: 0.0576 - val_accuracy: 0.9908\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0594 - val_accuracy: 0.9890\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0502 - val_accuracy: 0.9915\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 8.9327e-04 - accuracy: 0.9996 - val_loss: 0.0697 - val_accuracy: 0.9906\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0520 - val_accuracy: 0.9906\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0637 - val_accuracy: 0.9912\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0560 - val_accuracy: 0.9923\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0475 - val_accuracy: 0.9923\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.4572e-04 - accuracy: 0.9999 - val_loss: 0.0486 - val_accuracy: 0.9925\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 9.6577e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9924\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0498 - accuracy: 0.9930\n",
      "Test accuracy: 0.9929999709129333\n"
     ]
    }
   ],
   "source": [
    "# Using Tensorflow Library:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocessing data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Model Building\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Model Compilation\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=30, validation_split=0.2)\n",
    "\n",
    "# Model Evaluation uisng set test\n",
    "_, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mErFOvRq1BZC",
    "outputId": "69e2f17e-677d-4436-d7bd-4746305dd988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 399851038.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 23789413.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 161926747.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 18230171.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Train Loss: 0.1004, Train Accuracy: 96.95%, Test Loss: 0.0485, Test Accuracy: 98.48%\n",
      "Epoch 2/30: Train Loss: 0.0406, Train Accuracy: 98.77%, Test Loss: 0.0297, Test Accuracy: 99.16%\n",
      "Epoch 3/30: Train Loss: 0.0288, Train Accuracy: 99.13%, Test Loss: 0.0449, Test Accuracy: 98.80%\n",
      "Epoch 4/30: Train Loss: 0.0250, Train Accuracy: 99.26%, Test Loss: 0.0639, Test Accuracy: 98.17%\n",
      "Epoch 5/30: Train Loss: 0.0201, Train Accuracy: 99.39%, Test Loss: 0.0342, Test Accuracy: 98.88%\n",
      "Epoch 6/30: Train Loss: 0.0177, Train Accuracy: 99.46%, Test Loss: 0.0289, Test Accuracy: 99.20%\n",
      "Epoch 7/30: Train Loss: 0.0146, Train Accuracy: 99.53%, Test Loss: 0.0265, Test Accuracy: 99.28%\n",
      "Epoch 8/30: Train Loss: 0.0145, Train Accuracy: 99.55%, Test Loss: 0.0211, Test Accuracy: 99.35%\n",
      "Epoch 9/30: Train Loss: 0.0113, Train Accuracy: 99.66%, Test Loss: 0.0384, Test Accuracy: 99.06%\n",
      "Epoch 10/30: Train Loss: 0.0129, Train Accuracy: 99.57%, Test Loss: 0.0427, Test Accuracy: 98.81%\n",
      "Epoch 11/30: Train Loss: 0.0090, Train Accuracy: 99.74%, Test Loss: 0.0212, Test Accuracy: 99.49%\n",
      "Epoch 12/30: Train Loss: 0.0103, Train Accuracy: 99.70%, Test Loss: 0.0221, Test Accuracy: 99.34%\n",
      "Epoch 13/30: Train Loss: 0.0098, Train Accuracy: 99.69%, Test Loss: 0.0294, Test Accuracy: 99.25%\n",
      "Epoch 14/30: Train Loss: 0.0081, Train Accuracy: 99.73%, Test Loss: 0.0322, Test Accuracy: 99.30%\n",
      "Epoch 15/30: Train Loss: 0.0064, Train Accuracy: 99.80%, Test Loss: 0.0362, Test Accuracy: 99.08%\n",
      "Epoch 16/30: Train Loss: 0.0051, Train Accuracy: 99.81%, Test Loss: 0.0374, Test Accuracy: 99.16%\n",
      "Epoch 17/30: Train Loss: 0.0069, Train Accuracy: 99.78%, Test Loss: 0.0261, Test Accuracy: 99.31%\n",
      "Epoch 18/30: Train Loss: 0.0084, Train Accuracy: 99.76%, Test Loss: 0.0261, Test Accuracy: 99.31%\n",
      "Epoch 19/30: Train Loss: 0.0039, Train Accuracy: 99.88%, Test Loss: 0.0267, Test Accuracy: 99.38%\n",
      "Epoch 20/30: Train Loss: 0.0032, Train Accuracy: 99.91%, Test Loss: 0.0235, Test Accuracy: 99.38%\n",
      "Epoch 21/30: Train Loss: 0.0051, Train Accuracy: 99.84%, Test Loss: 0.0293, Test Accuracy: 99.30%\n",
      "Epoch 22/30: Train Loss: 0.0050, Train Accuracy: 99.84%, Test Loss: 0.0293, Test Accuracy: 99.33%\n",
      "Epoch 23/30: Train Loss: 0.0049, Train Accuracy: 99.85%, Test Loss: 0.0256, Test Accuracy: 99.36%\n",
      "Epoch 24/30: Train Loss: 0.0044, Train Accuracy: 99.88%, Test Loss: 0.0300, Test Accuracy: 99.30%\n",
      "Epoch 25/30: Train Loss: 0.0026, Train Accuracy: 99.92%, Test Loss: 0.0238, Test Accuracy: 99.47%\n",
      "Epoch 26/30: Train Loss: 0.0012, Train Accuracy: 99.97%, Test Loss: 0.0362, Test Accuracy: 99.28%\n",
      "Epoch 27/30: Train Loss: 0.0049, Train Accuracy: 99.84%, Test Loss: 0.0325, Test Accuracy: 99.33%\n",
      "Epoch 28/30: Train Loss: 0.0051, Train Accuracy: 99.86%, Test Loss: 0.0300, Test Accuracy: 99.34%\n",
      "Epoch 29/30: Train Loss: 0.0038, Train Accuracy: 99.87%, Test Loss: 0.0276, Test Accuracy: 99.37%\n",
      "Epoch 30/30: Train Loss: 0.0027, Train Accuracy: 99.93%, Test Loss: 0.0344, Test Accuracy: 99.32%\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch Library:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import models\n",
    "\n",
    "# Random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = MNIST(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=ToTensor())\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.fc = nn.Linear(512, 10)\n",
    "\n",
    "# The loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(train_dataset)\n",
    "\n",
    "    # Model Evaluation\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_dataset)\n",
    "    test_accuracy = 100.0 * test_correct / len(test_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
